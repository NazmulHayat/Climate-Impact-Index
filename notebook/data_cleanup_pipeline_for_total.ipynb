{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358ca965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def build_hazard_impact(\n",
    "    df,\n",
    "    hazard_name,\n",
    "    period_size=5,\n",
    "    min_events=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete pipeline:\n",
    "    - removes nulls\n",
    "    - aggregates\n",
    "    - standardizes\n",
    "    - outputs total number of deaths and affected people\n",
    "\n",
    "    Required columns:\n",
    "    country | year | affected | death\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop rows where both affected & death are missing\n",
    "    df = df.dropna(subset=[\"affected\", \"death\"], how=\"all\")\n",
    "    \n",
    "    df = df.sort_values([\"country\", \"year\"])\n",
    "\n",
    "    # CREATE TIME PERIOD (5-year bins)\n",
    "    df[\"period\"] = (df[\"year\"] // period_size) * period_size\n",
    "\n",
    "    # AGGREGATE WITHIN COUNTRYâ€“PERIOD\n",
    "    agg = (\n",
    "        df.groupby([\"country\", \"period\"])\n",
    "          .agg(\n",
    "              events=(\"year\", \"count\"),\n",
    "              total_deaths=(\"death\", \"sum\"),\n",
    "              total_affected=(\"affected\", \"sum\")\n",
    "          )\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    # Filter by minimum events\n",
    "    agg = agg[agg[\"events\"] >= min_events]\n",
    "\n",
    "    # Rename columns to include hazard name\n",
    "    agg = agg.rename(columns={\n",
    "        \"total_affected\": f\"{hazard_name}_total_affected\",\n",
    "        \"total_deaths\": f\"{hazard_name}_total_deaths\"\n",
    "    })\n",
    "\n",
    "    return agg[[\"country\", \"period\", f\"{hazard_name}_total_affected\", f\"{hazard_name}_total_deaths\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46448d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extreme temperature data processed:\n",
      "       country  period  extreme_temp_total_affected  extreme_temp_total_deaths\n",
      "0  Afghanistan    1990                        200.0                      224.0\n",
      "1  Afghanistan    2000                     200000.0                      327.0\n",
      "2  Afghanistan    2005                     170684.0                     1338.0\n",
      "3  Afghanistan    2010                         68.0                       45.0\n",
      "4  Afghanistan    2020                     327422.0                     1363.0\n",
      "\n",
      "Total rows: 505\n"
     ]
    }
   ],
   "source": [
    "extreme_temp_aff = pd.read_csv('../data/raw/total_count/total-affected-by-extreme-temperatures/affected.csv')\n",
    "extreme_temp_death = pd.read_csv('../data/raw/total_count/deaths-from-extreme-temperatures/deaths.csv')\n",
    "\n",
    "extreme_temp_aff.rename(\n",
    "    columns={\n",
    "        'total_affected_temperature': 'affected'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "extreme_temp_death.rename(\n",
    "    columns={\n",
    "        'deaths_temperature': 'death'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "extreme_temp_df = pd.merge(extreme_temp_aff, extreme_temp_death, on=['country', 'year'])\n",
    "extreme_temp_final = build_hazard_impact(extreme_temp_df, \"extreme_temp\")\n",
    "extreme_temp_final.to_csv(\"../data/processed/extreme_temp_data.csv\", index=False)\n",
    "print(\"Extreme temperature data processed:\")\n",
    "print(extreme_temp_final.head())\n",
    "print(f\"\\nTotal rows: {len(extreme_temp_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3aaab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drought data processed:\n",
      "       country  period  drought_total_affected  drought_total_deaths\n",
      "0  Afghanistan    1965                 48000.0                   0.0\n",
      "1  Afghanistan    1970                     0.0                   0.0\n",
      "2  Afghanistan    2000               2580000.0                  37.0\n",
      "3  Afghanistan    2005               2180000.0                   0.0\n",
      "4  Afghanistan    2010               1750000.0                   0.0\n",
      "\n",
      "Total rows: 860\n"
     ]
    }
   ],
   "source": [
    "# DROUGHT DATA PROCESSING\n",
    "drought_aff = pd.read_csv('../data/raw/total_count/total-affected-by-drought/affected.csv')\n",
    "drought_death = pd.read_csv('../data/raw/total_count/deaths-from-drought/deaths.csv')\n",
    "\n",
    "drought_aff.rename(\n",
    "    columns={\n",
    "        'total_affected_drought': 'affected'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "drought_death.rename(\n",
    "    columns={\n",
    "        'deaths_drought': 'death'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "drought_df = pd.merge(drought_aff, drought_death, on=['country', 'year'])\n",
    "drought_final = build_hazard_impact(drought_df, \"drought\")\n",
    "drought_final.to_csv(\"../data/processed/drought_data.csv\", index=False)\n",
    "print(\"Drought data processed:\")\n",
    "print(drought_final.head())\n",
    "print(f\"\\nTotal rows: {len(drought_final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcc6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood data processed:\n",
      "       country  period  flood_total_affected  flood_total_deaths\n",
      "0  Afghanistan    1955                   0.0                51.0\n",
      "1  Afghanistan    1960                   0.0               107.0\n",
      "2  Afghanistan    1970              250000.0               150.0\n",
      "3  Afghanistan    1975              351684.0               171.0\n",
      "4  Afghanistan    1980               30000.0                 0.0\n",
      "\n",
      "Total rows: 1652\n"
     ]
    }
   ],
   "source": [
    "# FLOOD DATA PROCESSING\n",
    "flood_aff = pd.read_csv('../data/raw/total_count/total-affected-by-floods/affected.csv')\n",
    "flood_death = pd.read_csv('../data/raw/total_count/deaths-from-floods/deaths.csv')\n",
    "\n",
    "flood_aff.rename(\n",
    "    columns={\n",
    "        'total_affected_flood': 'affected'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "flood_death.rename(\n",
    "    columns={\n",
    "        'deaths_flood': 'death'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "flood_df = pd.merge(flood_aff, flood_death, on=['country', 'year'])\n",
    "flood_final = build_hazard_impact(flood_df, \"flood\")\n",
    "flood_final.to_csv(\"../data/processed/flood_data.csv\", index=False)\n",
    "print(\"Flood data processed:\")\n",
    "print(flood_final.head())\n",
    "print(f\"\\nTotal rows: {len(flood_final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b1a4b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storm data processed:\n",
      "       country  period  storm_total_affected  storm_total_deaths\n",
      "0  Afghanistan    1990                   0.0                10.0\n",
      "1  Afghanistan    2005               22656.0               331.0\n",
      "2  Afghanistan    2010                   5.0                84.0\n",
      "3  Afghanistan    2015                9055.0                67.0\n",
      "4  Afghanistan    2020                7481.0                13.0\n",
      "\n",
      "Total rows: 1584\n"
     ]
    }
   ],
   "source": [
    "# STORM DATA PROCESSING\n",
    "storm_aff = pd.read_csv('../data/raw/total_count/total-affected-by-storms/affected.csv')\n",
    "storm_death = pd.read_csv('../data/raw/total_count/deaths-from-storms/deaths.csv')\n",
    "\n",
    "storm_aff.rename(\n",
    "    columns={\n",
    "        'total_affected_storm': 'affected'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "storm_death.rename(\n",
    "    columns={\n",
    "        'deaths_storm': 'death'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "storm_df = pd.merge(storm_aff, storm_death, on=['country', 'year'])\n",
    "storm_final = build_hazard_impact(storm_df, \"storm\")\n",
    "storm_final.to_csv(\"../data/processed/storms_data.csv\", index=False)\n",
    "print(\"Storm data processed:\")\n",
    "print(storm_final.head())\n",
    "print(f\"\\nTotal rows: {len(storm_final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9cbf022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged dataset:\n",
      "\n",
      "Total rows: 2440\n",
      "\n",
      "Columns: ['country', 'period', 'extreme_temp_total_affected', 'extreme_temp_total_deaths', 'drought_total_affected', 'drought_total_deaths', 'flood_total_affected', 'flood_total_deaths', 'storm_total_affected', 'storm_total_deaths']\n"
     ]
    }
   ],
   "source": [
    "# MERGE ALL HAZARDS INTO FINAL DATASET\n",
    "# Merge all hazards on country and period\n",
    "final_df = extreme_temp_final.copy()\n",
    "\n",
    "final_df = final_df.merge(drought_final, on=['country', 'period'], how='outer')\n",
    "final_df = final_df.merge(flood_final, on=['country', 'period'], how='outer')\n",
    "final_df = final_df.merge(storm_final, on=['country', 'period'], how='outer')\n",
    "\n",
    "# Fill NaN values with 0 (no impact for that hazard in that period)\n",
    "final_df = final_df.fillna(0)\n",
    "\n",
    "# Sort by country and period\n",
    "final_df = final_df.sort_values(['country', 'period']).reset_index(drop=True)\n",
    "\n",
    "# Save final merged dataset\n",
    "final_df.to_csv(\"../data/processed/final_total_data.csv\", index=False)\n",
    "print(\"Final merged dataset:\")\n",
    "print(f\"\\nTotal rows: {len(final_df)}\")\n",
    "print(f\"\\nColumns: {list(final_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5882d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96348f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b3322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016240d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef8c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb45fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d12a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
